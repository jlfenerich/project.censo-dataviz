{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data from API | Census 1991, 2000 e 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://servicodados.ibge.gov.br/api/v3/agregados/156/periodos/1991|2000|2010/variaveis/134?localidades=N6[all]'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure the request was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful request!\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(\"Successful request!\")\n",
    "else:\n",
    "    print(f\"Request fail with status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanning and transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jlfen\\AppData\\Local\\Temp\\ipykernel_37040\\2782770001.py:36: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df_existing = pd.read_csv(csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
      "C:\\Users\\jlfen\\AppData\\Local\\Temp\\ipykernel_37040\\2782770001.py:36: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df_existing = pd.read_csv(csv_path, error_bad_lines=False, warn_bad_lines=True)\n"
     ]
    }
   ],
   "source": [
    "data = response.json()\n",
    "\n",
    "# Flatten data\n",
    "flattened_data = []\n",
    "for item in data[0]['resultados'][0]['series']:\n",
    "    id = item['localidade']['id']\n",
    "    name = item['localidade']['nome']\n",
    "    \n",
    "    # Iterate over years in the 'serie' dictionary\n",
    "    for year, population in item['serie'].items():\n",
    "        # Convert '...' to NaN\n",
    "        if population == '...':\n",
    "            population = np.nan\n",
    "        flattened_data.append({'id': id, 'name': name, 'year': year, 'population': population})\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Split 'name' into 'city' and 'state'\n",
    "df[['city', 'state']] = df['name'].str.split(' - ', expand=True)\n",
    "\n",
    "# Convert the 'year' and 'population' columns\n",
    "df['year'] = df['year'].astype(int)\n",
    "df['population'] = df['population'].fillna(-1).astype(int)\n",
    "df['population'] = df['population'].replace(-1, np.nan)\n",
    "\n",
    "# Drop the 'name' columns\n",
    "df = df.drop(columns=['name'])\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_path = 'C:\\\\Users\\\\jlfen\\\\OneDrive\\\\Documentos\\\\JoaoKasten\\\\005_applied_projects\\\\project.censo-dataviz\\\\data\\\\census_data.csv'\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "if os.path.exists(csv_path):\n",
    "    # Load existing data from CSV\n",
    "    df_existing = pd.read_csv(csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
    "    \n",
    "    # Combine new and existing data\n",
    "    df_combined = pd.concat([df_existing, df], ignore_index=True)\n",
    "    \n",
    "    # Remove duplicates based on 'id' and 'year' columns\n",
    "    df_combined.drop_duplicates(subset=['id', 'year'], inplace=True)\n",
    "    \n",
    "    # Save the combined DataFrame back to the CSV\n",
    "    df_combined.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "else:\n",
    "    # If the file doesn't exist, just save the new data\n",
    "    df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving _df_ to a csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
